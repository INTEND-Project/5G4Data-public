replicaCount: 1

image:
  repository: ghcr.io/arne-munch-ellingsen/rusty_llm
  pullPolicy: Always  # Changed to Always to force pull of latest tag
  tag: "latest"

# Image pull secrets for private registries (e.g., GHCR)
# Create the secret manually with:
# kubectl create secret docker-registry ghcr-secret --docker-server=ghcr.io --docker-username=<username> --docker-password=<token> -n <namespace>
imagePullSecrets:
  - name: ghcr-secret
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

podAnnotations:
  prometheus.io/scrape: 'true'
  prometheus.io/path: '/metrics'
  prometheus.io/port: '8081'

podSecurityContext: {}

securityContext: {}

service:
  type: LoadBalancer
  port: 8080
  targetPort: 8080

# Environment variables for the rusty_llm application
env:
  MODEL_THREADS: "12"
  HTTP_ADDRESS: "0.0.0.0:8080"
  PROMETHEUS_HTTP_ADDRESS: "0.0.0.0:8081"
  MODEL_MAX_TOKEN: "2048"
  RUST_LOG: "debug"
  MODEL_PROMPT_TEMPLATE: "<|system|> Using this information: {context} answer the following question. Use 3 paragraphs or less. <|end|><|user|> {query} <|end|><|assistant|>"
  DATA_PATH: "/home/data"  # Data is now included in the Docker image at /home/data
  # EMBEDDING_MODEL: "model/embed.gguf"
  # HTTP_WORKERS: "1"
  # INSTANCE_LABEL: "default"
  # MAIN_GPU: "0"
  # MODEL_GPU_LAYERS: "0"
  # MODEL_PATH: "model/model.gguf"

resources:
  requests:
    memory: 20Gi
  limits:
    memory: 20Gi

# Volume configuration
volumes:
  model:
    enabled: false  # Models are now included in the Docker image
    type: hostPath
    hostPath: /home/models
    mountPath: /app/model
  data:
    enabled: false  # Data is now included in the Docker image
    type: hostPath
    hostPath: /home/data
    mountPath: /app/data

# Prometheus monitoring
prometheus:
  enabled: true
  scrape: true
  path: /metrics
  port: 8081

nodeSelector: {}

tolerations: []

affinity: {}

# Open WebUI configuration
openWebUI:
  enabled: true
  image:
    repository: ghcr.io/open-webui/open-webui
    tag: main  # Using standard OpenWebUI image
    pullPolicy: Always
  replicaCount: 1
  service:
    type: NodePort
    port: 3000
    targetPort: 8080
    nodePort: 30873  # Direct NodePort access
  ingress:
    enabled: false  # Disabled - using NodePort instead
  env:
    WEBUI_AUTH: "false"
    ENABLE_OLLAMA_API: "false"
    OPENAI_API_BASE_URL: ""  # If empty, will use service name template: http://<service-name>.<namespace>:8080/v1
    DEFAULT_MODELS: "rusty_llm"
  volumes:
    webui:
      enabled: true
      type: hostPath
      hostPath: /home/open-webui/  # Update this to your desired host path
      mountPath: /app/backend/data

# Connectivity test configuration
connectivityTest:
  enabled: false  # Set to true to enable connectivity test as a Helm test hook
  image:
    repository: curlimages/curl
    tag: latest
    pullPolicy: IfNotPresent
  hook: "test"  # Helm hook type: "test" runs with `helm test`, "post-install" runs after install
  deletePolicy: "before-hook-creation,hook-succeeded"  # Clean up after success
  ttlSecondsAfterFinished: 300  # Clean up job after 5 minutes
  backoffLimit: 3  # Retry up to 3 times on failure

